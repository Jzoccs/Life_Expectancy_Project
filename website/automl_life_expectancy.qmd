---
title: "Life Expectancy Model Comparison"
format:
  html:
    theme: cosmo
    toc: true
    toc-depth: 3
    code-fold: true
    embed-resources: true
jupyter: python3
execute:
  echo: false
  warning: false
  message: false
---

# Overview

This page compares several regression models trained to predict **life expectancy** from
GDP per capita, CO₂ emissions per capita, and year.

The models included are:

- Linear Regression (with standardization)
- FLAML AutoML restricted to:
  - `lgbm` (Light Gradient Boosting)
  - `rf` (Random Forest)
  - `xgboost` (Extreme Gradient Boosting)

The script `src/models/train_life_expectancy_models.py` was run beforehand to:

1. Load and clean the data  
2. Train all models  
3. Evaluate each model on a held-out test set  
4. Save the metrics to `data/processed/model_comparison_metrics.csv`

Below we load those metrics and visualize the differences.

```{python}
#| label: load-metrics

import pandas as pd

# Path is relative to the website/ folder
metrics_path = "../data/processed/model_comparison_metrics.csv"
metrics_df = pd.read_csv(metrics_path)

metrics_df
```
# Make a "long" version of the metrics for easier plotting

```{python}
#| label: metrics-long


long_df = metrics_df.melt(
id_vars="model",
value_vars=["rmse", "mae", "r2"],
var_name="metric",
value_name="value",
)

long_df

#| label: bar-charts
#| fig-cap: "RMSE, MAE, and R² for each model"

import plotly.express as px

# One combined bar chart with facets by metric

fig = px.bar(
            long_df,
            x="model",
            y="value",
            color="model",
            facet_col="metric",
            facet_col_wrap=3,
            text_auto=".3f",
            title="Model performance by metric",
            )

# Make it a bit nicer

fig.update_layout(
                showlegend=False,
                height=500,)
fig.update_yaxes(matches=None)  # allow different ranges per facet

fig.show()


#| label: best-models
#| echo: false

from IPython.display import Markdown

# Lower is better for RMSE & MAE, higher is better for R²

best_rmse_row = metrics_df.loc[metrics_df["rmse"].idxmin()]
best_mae_row = metrics_df.loc[metrics_df["mae"].idxmin()]
best_r2_row = metrics_df.loc[metrics_df["r2"].idxmax()]

summary_md = f"""
```
## Which model performs best?

Based on the held-out test set:

* **Lowest RMSE**: `{best_rmse_row['model']}`
  ```{python}(RMSE = {best_rmse_row['rmse']:.3f})
  ```

* **Lowest MAE**: `{best_mae_row['model']}`
 ```{python} (MAE = {best_mae_row['mae']:.3f})
```

* **Highest R²**: `{best_r2_row['model']}`
  (R² = {best_r2_row['r2']:.3f})

Remember:

* **RMSE** and **MAE** (lower is better) measure how far predictions are from
  true life expectancy, in years.
* **R²** (higher is better) measures how much of the variability in life
  expectancy is explained by the model.
  """

Markdown(summary_md)
